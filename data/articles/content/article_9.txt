HTTP(S) load balancing provides global load balancing for HTTP(S) requests destined for your instances. You can configure URL rules that route some URLs to one set of instances and route other URLs to other instances. Requests are always routed to the instance group that is closest to the user, provided that group has enough capacity and is appropriate for the request. If the closest group does not have enough capacity, the request is sent to the closest group that does have capacity. HTTP requests can be load balanced based on port 80 or port 8080. HTTPS requests can be load balanced on port 443. The load balancer acts as an HTTP/2 to HTTP/1.1 translation layer, which means that the web servers always see and respond to HTTP/1.1 requests, but that requests from the browser can be HTTP/1.0, HTTP/1.1, or HTTP/2. HTTP(S) load balancing does not support WebSocket. You can use WebSocket traffic with Network load balancing . Contents Before you begin HTTP(S) load balancing uses instance groups to organize instances. Make sure you are familiar with instance groups before you use load balancing. Fundamentals Overview An HTTP(S) load balancer is composed of several components. The following diagram illustrates the architecture of a complete HTTP(S) load balancer: The following sections describe how each component works together to make up each type of load balancer. For a detailed description of each component, see Components below. HTTP load balancing A complete HTTP load balancer is structured as follows: A global forwarding rule directs incoming requests to a target HTTP proxy . The target HTTP proxy checks each request against a URL map to determine the appropriate backend service for the request. The backend service directs each request to an appropriate backend based on serving capacity, zone, and instance health of its attached backends. The health of each backend instance is verified using either an HTTP health check or an HTTPS health check. If the backend service is configured to use the latter, the request will be encrypted on its way to the backend instance. In addition, you must create a firewall rule to enable traffic to your HTTP load balancer. The rule should enable traffic on the port your global forwarding rule has been configured to use (either 80 or 8080). HTTPS load balancing An HTTPS load balancer shares the same basic structure as an HTTP load balancer (described above), but differs in the following ways: Uses a target HTTPS proxy instead of a target HTTP proxy Requires a signed SSL certificate for the load balancer Requires a firewall rule that enables traffic on port 443 The client SSL session terminates at the load balancer. Sessions between the load balancer and the instance can either be HTTPS (recommended) or HTTP. If HTTPS, each instance must have a certificate. Components Global forwarding rules and addresses Global forwarding rules route traffic by IP address, port, and protocol to a load balancing configuration consisting of a target proxy, URL map, and one or more backend services. Each global forwarding rule provides a single global IP address that can be used in DNS records for your application. No DNS-based load balancing is required. You can either specify the IP address to be used or let Google Compute Engine assign one for you. Target proxies Target proxies terminate HTTP(S) connections from clients, and are referenced by one or more global forwarding rules and route the incoming requests to a URL map. The proxies set HTTP request/response headers as follows: Via: 1.1 google (requests and responses) X-Forwarded-Proto: [http | https] (requests only) X-Forwarded-For: <client IP(s)>, <global forwarding rule external IP> (requests only) Can be a comma-separated list of IP addresses depending on the X-Forwarded-For entries appended by the intermediaries the client is traveling through. The first element in the <client IP(s)> section shows the origin address. X-Cloud-Trace-Context: <trace-id>/<span-id>;<trace-options> (requests only) Parameters for Stackdriver Trace . URL maps URL maps define matching patterns for URL-based routing of requests to the appropriate backend services. A default service is defined to handle any requests that do not match a specified host rule or path matching rule. In some situations, such as the cross-region load balancing example , you might not define any URL rules and rely only on the default service. For content-based routing of traffic, the URL map allows you to divide your traffic by examining the URL components to send requests to different sets of backends. SSL certificates SSL certificates are used by target HTTPS proxies to securely route incoming HTTPS requests to backend services defined in a URL map. Backend services Backend services direct incoming traffic to one or more attached backends. Each backend is composed of an instance group and additional serving capacity metadata. Backend serving capacity can be based on CPU or requests per second (RPS) . Each backend service also specifies which health checks will be performed against the available instances. HTTP(S) load balancing supports Compute Engine Autoscaler , which allows users to perform autoscaling on the instance groups in a backend service. For more information, see Scaling Based on HTTP load balancing serving capacity . Load distribution algorithm HTTP(S) load balancing provides two methods of determining instance load. Within the backend service object, the balancingMode property selects between the requests per second (RPS) and CPU utilization modes. Both modes allow a maximum value to be specified; the HTTP load balancer will try to ensure that load remains under the limit, but short bursts above the limit can occur during failover or load spike events. Incoming requests are sent to the region closest to the user that has remaining capacity. If more than one zone is configured with backends in a region, the traffic is distributed across the instance groups in each zone according to each group's capacity. Within the zone, the requests are spread evenly over the instances using a round-robin algorithm. Round-robin distribution can be overridden by configuring session affinity . Session affinity Alpha This is an Alpha release of HTTP(S) Load Balancing Session Affinity. This feature might be changed in backward-incompatible ways and is not recommended for production use. It is not subject to any SLA or deprecation policy. Request to be whitelisted to use this feature . Session affinity sends all request from the same client to the same virtual machine instance as long as the instance stays healthy and has capacity. Google Cloud HTTP(S) Load Balancing offers two types of session affinity: Interfaces Your HTTP(S) load balancing service can be configured and updated through the following interfaces: The gcloud tool : gcloud is a command-line tool included in the Cloud SDK . The HTTP(S) load balancing documentation calls on this tool frequently to accomplish tasks. For a complete overview of gcloud documentation, see the gcloud Tool Guide . You can find commands related to load balancing in the gcloud compute and gcloud preview command groups. You can also get detailed help for any gcloud command by using the --help flag: gcloud compute http-health-checks create --help The Google Cloud Platform Console : Load balancing tasks can be accomplished through the Google Cloud Platform Console . The REST API : All load balancing tasks can be accomplished using the Google Compute Engine API. The API reference docs describe the resources and methods available to you. TLS support A HTTPS target proxy accepts only TLS 1.0 and up when terminating client SSL requests. It speaks only TLS 1.0 and up to the backend service when the backend protocol is HTTPS. Logging Alpha This is an Alpha release of Google Cloud HTTP(S) Load Balancing Logging. This feature might be changed in backward-incompatible ways and is not recommended for production use. It is not subject to any SLA or deprecation policy. Request to be whitelisted to use this feature . Each HTTP(S) request is logged via Google Cloud Logging . If you have been accepted into the Alpha testing phase, logging is automatic and does not need to be enabled. How to view logs To view logs, go to the Logs Viewer in the Cloud Platform Console. HTTP(S) logs are indexed first by forwarding rule , then by URL map . To see all logs, in the first pull-down menu select Load Balancing > All forwarding rules . To see logs for just one forwarding rule, select a single forwarding rule name from the list. To see logs for just one URL map used by a forwarding rule, select Load Balancing and choose the forwarding rule and URL map of interest. What is logged In addition to general information contained in most logs, such as severity, project ID, project number, and timestamp, HTTP(S) load balancing logs contain HttpRequest log fields. Log fields of type boolean typically only appear if they have a value of true . If a boolean field has a value of false , that field is omitted from the log. UTF-8 encoding is enforced for these fields. Characters that are not UTF-8 characters are replaced with question marks. Next steps The following guides demonstrate two different scenarios using the HTTP(S) load balancing service. These scenarios provide a practical context for HTTP(S) load balancing and demonstrate how you might set up load balancing for your specific needs. Cross-region load balancing You can use a global IP address that can intelligently route users based on proximity. For example, if you set up instances in North America, Europe, and Asia, users around the world will be automatically sent to the backends closest to them, assuming those instances have enough capacity. If the closest instances do not have enough capacity, cross-region load balancing automatically forwards users to the next closest region. Get started with cross-region load balancing Content-based load balancing Content-based or content-aware load balancing uses HTTP(S) load balancing to distribute traffic to different instances based on the incoming HTTP(S) URL. For example, you can set up some instances to handle your video content and another set to handle everything else. You can configure your load balancer to direct traffic for example.com/video to the video servers and example.com/ to the default servers. Get started with content-based load balancing Content-based and cross-region load-balancing can work together by using multiple backend services and multiple regions. You can build on top of the scenarios above to configure your own load balancing configuration that meets your needs. Notes and Restrictions HTTP(S) load balancing does not support HTTP/1.1 100 Continue response. This might affect multipart POST. The load balancing configuration automatically creates firewall rules if the instance operating system is a Compute Engine image. If not, you have to create the firewall rules manually. Load balancing does not keep instances in sync. You must set up your own mechanisms, such as using Deployment Manager , for ensuring that your instances have consistent configurations and data. Troubleshooting Traffic from the load balancer to your instances has an IP address in the range of 130.211.0.0/22. When viewing logs on your load balanced instances, you will not see the source address of the original client. Instead, you will see source addresses from this range.